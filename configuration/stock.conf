input {
 # beat에서 데이터를 받을 logstash의 port지정
  beats {
    port => 5044 
  }
}

filter {
  mutate {
    # 실제 데이터는 "message" 필드로 오기 때문에 csv형태의 내용을 분할하여 새로운 이름으로 필드를 추가 
    split => [ "message",  "," ] 
    add_field => {
      "code" => "%{[message][0]}"
      "name" => "%{[message][1]}"
      "date" => "%{[message][2]}"
      "close" => "%{[message][3]}"
      "open" => "%{[message][4]}"
      "high" => "%{[message][5]}"
      "low" => "%{[message][6]}"
      "volume" => "%{[message][7]}"
    }

    # 기본으로 전송되는 데이터 분석에 불필요한 필드 제거
    remove_field => ["ecs", "host", "@version", "agent", "log", "tags",  "input", "message"]
  }

  # "date" 필드를 이용하여 Elasticsearch에서 인식할 수 있는 date 타입의 형태로 필드를 추가
  date {
    match => [ "date", "MM.dd"]
    timezone => "Asia/Seoul"
    locale => "ko"
    target => "convert_date"
  }

  # Kibana에서 데이터 분석시 필요하기 때문에 숫자 타입으로 변경
  mutate {
    convert => {
      "close" => "integer"
      "open" => "integer"
      "high" => "integer"
      "low" => "integer"
      "volume" => "integer"
    }
    remove_field => [ "@timestamp" ]
  }
}

output {

  # 콘솔창에 어떤 데이터들로 필터링 되었는지 확인
  stdout {
          codec => rubydebug
  }

  # 위에서 설치한 Elasticsearch 로 "covid-19" 라는 이름으로 인덱싱 
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "stock_info"
  }
}

